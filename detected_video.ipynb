{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "bAKjEfDXKpCm"
      },
      "outputs": [],
      "source": [
        "!mkdir /content/data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "N0nfM22TKv-U"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QCj2eqYjQfAE"
      },
      "source": [
        "### Video Object Detection 수행"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5-C59eTQfAE"
      },
      "source": [
        "#### 원본 영상 보기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z9dnZWC3QfAE"
      },
      "source": [
        "#### VideoCapture와 VideoWriter 설정하기\n",
        "* VideoCapture를 이용하여 Video를 frame별로 capture 할 수 있도록 설정\n",
        "* VideoCapture의 속성을 이용하여 Video Frame의 크기 및 FPS 설정.\n",
        "* VideoWriter를 위한 인코딩 코덱 설정 및 영상 write를 위한 설정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0gHk8SdcSXyQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c877d24-cc17-4e9c-f9c9-9ab6c713cbcf"
      },
      "source": [
        "video_input_path = '/content/data/golf_video.mp4'\n",
        "\n",
        "cap = cv2.VideoCapture(video_input_path)\n",
        "frame_cnt = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "print('총 Frame 갯수:', frame_cnt)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "총 Frame 갯수: 130\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1qNvV0LQfAF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ff3c352-91bd-4468-b41e-bdfafe24dd60"
      },
      "source": [
        "video_input_path = '/content/data/golf_video.mp4'\n",
        "video_output_path = './data/golf_video_cv01.mp4'\n",
        "\n",
        "cap = cv2.VideoCapture(video_input_path)\n",
        "\n",
        "codec = cv2.VideoWriter_fourcc(*'XVID')\n",
        "\n",
        "vid_size = (round(cap.get(cv2.CAP_PROP_FRAME_WIDTH)),round(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)))\n",
        "vid_fps = cap.get(cv2.CAP_PROP_FPS )\n",
        "\n",
        "vid_writer = cv2.VideoWriter(video_output_path, codec, vid_fps, vid_size)\n",
        "\n",
        "frame_cnt = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "print('총 Frame 갯수:', frame_cnt)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "총 Frame 갯수: 130\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Faster-RCNN ResNet-50 다운로드 해서 사용\n",
        "\n",
        "*   weights : 링크?\n",
        "*   config : weights를 사용할 수 있게 설명해놓은것\n"
      ],
      "metadata": {
        "id": "HEXIYimRgf5Z"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1X4mTJRhQe_4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "446e4b08-f48c-464a-96c1-bb845b682fed"
      },
      "source": [
        "!mkdir ./pretrained\n",
        "!wget -O ./pretrained/faster_rcnn_resnet50_coco_2018_01_28.tar.gz http://download.tensorflow.org/models/object_detection/faster_rcnn_resnet50_coco_2018_01_28.tar.gz\n",
        "!wget -O ./pretrained/config_graph.pbtxt https://raw.githubusercontent.com/opencv/opencv_extra/master/testdata/dnn/faster_rcnn_resnet50_coco_2018_01_28.pbtxt"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-03-18 15:28:27--  http://download.tensorflow.org/models/object_detection/faster_rcnn_resnet50_coco_2018_01_28.tar.gz\n",
            "Resolving download.tensorflow.org (download.tensorflow.org)... 142.251.180.207, 108.177.112.207, 74.125.124.207, ...\n",
            "Connecting to download.tensorflow.org (download.tensorflow.org)|142.251.180.207|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 381355771 (364M) [application/x-tar]\n",
            "Saving to: ‘./pretrained/faster_rcnn_resnet50_coco_2018_01_28.tar.gz’\n",
            "\n",
            "./pretrained/faster 100%[===================>] 363.69M   123MB/s    in 3.0s    \n",
            "\n",
            "2024-03-18 15:28:30 (123 MB/s) - ‘./pretrained/faster_rcnn_resnet50_coco_2018_01_28.tar.gz’ saved [381355771/381355771]\n",
            "\n",
            "--2024-03-18 15:28:30--  https://raw.githubusercontent.com/opencv/opencv_extra/master/testdata/dnn/faster_rcnn_resnet50_coco_2018_01_28.pbtxt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 90893 (89K) [text/plain]\n",
            "Saving to: ‘./pretrained/config_graph.pbtxt’\n",
            "\n",
            "./pretrained/config 100%[===================>]  88.76K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2024-03-18 15:28:30 (3.01 MB/s) - ‘./pretrained/config_graph.pbtxt’ saved [90893/90893]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "압축파일 풀기"
      ],
      "metadata": {
        "id": "Mhn9EHXxhL0j"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mn95ff8JuX3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e974133-d654-4ce7-e156-7a7a4734b7c6"
      },
      "source": [
        "!tar -xvf ./pretrained/faster*.tar.gz -C ./pretrained"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "faster_rcnn_resnet50_coco_2018_01_28/\n",
            "faster_rcnn_resnet50_coco_2018_01_28/model.ckpt.index\n",
            "faster_rcnn_resnet50_coco_2018_01_28/checkpoint\n",
            "faster_rcnn_resnet50_coco_2018_01_28/pipeline.config\n",
            "faster_rcnn_resnet50_coco_2018_01_28/model.ckpt.data-00000-of-00001\n",
            "faster_rcnn_resnet50_coco_2018_01_28/model.ckpt.meta\n",
            "faster_rcnn_resnet50_coco_2018_01_28/saved_model/\n",
            "faster_rcnn_resnet50_coco_2018_01_28/saved_model/saved_model.pb\n",
            "faster_rcnn_resnet50_coco_2018_01_28/saved_model/variables/\n",
            "faster_rcnn_resnet50_coco_2018_01_28/frozen_inference_graph.pb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0LFdN3MQe_5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e54095f-b972-4658-b1d0-6abfd72ffd21"
      },
      "source": [
        "!pwd\n",
        "!ls -lia ./pretrained/faster_rcnn_resnet50_coco_2018_01_28"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "total 296076\n",
            "5636186 drwxr-xr-x 3 345018 5000      4096 Feb  1  2018 .\n",
            "5636182 drwxr-xr-x 3 root   root      4096 Mar 18 15:28 ..\n",
            "5636188 -rw-r--r-- 1 345018 5000        77 Feb  1  2018 checkpoint\n",
            "5636195 -rw-r--r-- 1 345018 5000 120549957 Feb  1  2018 frozen_inference_graph.pb\n",
            "5636190 -rw-r--r-- 1 345018 5000 176914228 Feb  1  2018 model.ckpt.data-00000-of-00001\n",
            "5636187 -rw-r--r-- 1 345018 5000     14460 Feb  1  2018 model.ckpt.index\n",
            "5636191 -rw-r--r-- 1 345018 5000   5675175 Feb  1  2018 model.ckpt.meta\n",
            "5636189 -rw-r--r-- 1 345018 5000      3240 Feb  1  2018 pipeline.config\n",
            "5636192 drwxr-xr-x 3 345018 5000      4096 Feb  1  2018 saved_model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yqvx54DBQe_7"
      },
      "source": [
        "cv_net = cv2.dnn.readNetFromTensorflow('./pretrained/faster_rcnn_resnet50_coco_2018_01_28/frozen_inference_graph.pb',\n",
        "                                     './pretrained/config_graph.pbtxt')"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wf_DxJfaQe_9"
      },
      "source": [
        "#### coco 데이터 세트의 클래스id별 클래스명 지정."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "brOMVMUJQe_-"
      },
      "source": [
        "# OpenCV Yolo용\n",
        "labels_to_names_seq = {0:'person',1:'bicycle',2:'car',3:'motorbike',4:'aeroplane',5:'bus',6:'train',7:'truck',8:'boat',9:'traffic light',10:'fire hydrant',\n",
        "                        11:'stop sign',12:'parking meter',13:'bench',14:'bird',15:'cat',16:'dog',17:'horse',18:'sheep',19:'cow',20:'elephant',\n",
        "                        21:'bear',22:'zebra',23:'giraffe',24:'backpack',25:'umbrella',26:'handbag',27:'tie',28:'suitcase',29:'frisbee',30:'skis',\n",
        "                        31:'snowboard',32:'sports ball',33:'kite',34:'baseball bat',35:'baseball glove',36:'skateboard',37:'surfboard',38:'tennis racket',39:'bottle',40:'wine glass',\n",
        "                        41:'cup',42:'fork',43:'knife',44:'spoon',45:'bowl',46:'banana',47:'apple',48:'sandwich',49:'orange',50:'broccoli',\n",
        "                        51:'carrot',52:'hot dog',53:'pizza',54:'donut',55:'cake',56:'chair',57:'sofa',58:'pottedplant',59:'bed',60:'diningtable',\n",
        "                        61:'toilet',62:'tvmonitor',63:'laptop',64:'mouse',65:'remote',66:'keyboard',67:'cell phone',68:'microwave',69:'oven',70:'toaster',\n",
        "                        71:'sink',72:'refrigerator',73:'book',74:'clock',75:'vase',76:'scissors',77:'teddy bear',78:'hair drier',79:'toothbrush' }"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5VsqWSUnQe__"
      },
      "source": [
        "# OpenCV Tensorflow Faster-RCNN용\n",
        "labels_to_names_0 = {0:'person',1:'bicycle',2:'car',3:'motorcycle',4:'airplane',5:'bus',6:'train',7:'truck',8:'boat',9:'traffic light',\n",
        "                    10:'fire hydrant',11:'street sign',12:'stop sign',13:'parking meter',14:'bench',15:'bird',16:'cat',17:'dog',18:'horse',19:'sheep',\n",
        "                    20:'cow',21:'elephant',22:'bear',23:'zebra',24:'giraffe',25:'hat',26:'backpack',27:'umbrella',28:'shoe',29:'eye glasses',\n",
        "                    30:'handbag',31:'tie',32:'suitcase',33:'frisbee',34:'skis',35:'snowboard',36:'sports ball',37:'kite',38:'baseball bat',39:'baseball glove',\n",
        "                    40:'skateboard',41:'surfboard',42:'tennis racket',43:'bottle',44:'plate',45:'wine glass',46:'cup',47:'fork',48:'knife',49:'spoon',\n",
        "                    50:'bowl',51:'banana',52:'apple',53:'sandwich',54:'orange',55:'broccoli',56:'carrot',57:'hot dog',58:'pizza',59:'donut',\n",
        "                    60:'cake',61:'chair',62:'couch',63:'potted plant',64:'bed',65:'mirror',66:'dining table',67:'window',68:'desk',69:'toilet',\n",
        "                    70:'door',71:'tv',72:'laptop',73:'mouse',74:'remote',75:'keyboard',76:'cell phone',77:'microwave',78:'oven',79:'toaster',\n",
        "                    80:'sink',81:'refrigerator',82:'blender',83:'book',84:'clock',85:'vase',86:'scissors',87:'teddy bear',88:'hair drier',89:'toothbrush',\n",
        "                    90:'hair brush'}"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eP6kC5qNQfAA"
      },
      "source": [
        "labels_to_names = {1:'person',2:'bicycle',3:'car',4:'motorcycle',5:'airplane',6:'bus',7:'train',8:'truck',9:'boat',10:'traffic light',\n",
        "                    11:'fire hydrant',12:'street sign',13:'stop sign',14:'parking meter',15:'bench',16:'bird',17:'cat',18:'dog',19:'horse',20:'sheep',\n",
        "                    21:'cow',22:'elephant',23:'bear',24:'zebra',25:'giraffe',26:'hat',27:'backpack',28:'umbrella',29:'shoe',30:'eye glasses',\n",
        "                    31:'handbag',32:'tie',33:'suitcase',34:'frisbee',35:'skis',36:'snowboard',37:'sports ball',38:'kite',39:'baseball bat',40:'baseball glove',\n",
        "                    41:'skateboard',42:'surfboard',43:'tennis racket',44:'bottle',45:'plate',46:'wine glass',47:'cup',48:'fork',49:'knife',50:'spoon',\n",
        "                    51:'bowl',52:'banana',53:'apple',54:'sandwich',55:'orange',56:'broccoli',57:'carrot',58:'hot dog',59:'pizza',60:'donut',\n",
        "                    61:'cake',62:'chair',63:'couch',64:'potted plant',65:'bed',66:'mirror',67:'dining table',68:'window',69:'desk',70:'toilet',\n",
        "                    71:'door',72:'tv',73:'laptop',74:'mouse',75:'remote',76:'keyboard',77:'cell phone',78:'microwave',79:'oven',80:'toaster',\n",
        "                    81:'sink',82:'refrigerator',83:'blender',84:'book',85:'clock',86:'vase',87:'scissors',88:'teddy bear',89:'hair drier',90:'toothbrush',\n",
        "                    91:'hair brush'}\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3xt4ptFQfAF"
      },
      "source": [
        "##### 총 Frame 별로 iteration 하면서 Object Detection 수행. 개별 frame별로 단일 이미지 Object Detection과 유사"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jVQ_4wySQfAF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4bb0ad3f-e0a6-4fba-f171-ce5504ffc16e"
      },
      "source": [
        "import time\n",
        "# bounding box의 테두리와 caption 글자색 지정\n",
        "green_color=(0, 255, 0)\n",
        "red_color=(0, 0, 255)\n",
        "\n",
        "while True:\n",
        "\n",
        "    hasFrame, img_frame = cap.read()\n",
        "    if not hasFrame:\n",
        "        print('더 이상 처리할 frame이 없습니다.')\n",
        "        break\n",
        "\n",
        "    rows = img_frame.shape[0]\n",
        "    cols = img_frame.shape[1]\n",
        "    # 원본 이미지 배열 BGR을 RGB로 변환하여 배열 입력\n",
        "    cv_net.setInput(cv2.dnn.blobFromImage(img_frame,  swapRB=True, crop=False))\n",
        "\n",
        "    start= time.time()\n",
        "    # Object Detection 수행하여 결과를 cv_out으로 반환\n",
        "    cv_out = cv_net.forward()\n",
        "    frame_index = 0\n",
        "    # detected 된 object들을 iteration 하면서 정보 추출\n",
        "    for detection in cv_out[0,0,:,:]:\n",
        "        score = float(detection[2])\n",
        "        class_id = int(detection[1])\n",
        "        # detected된 object들의 score가 0.5 이상만 추출\n",
        "        if score > 0.5:\n",
        "            # detected된 object들은 scale된 기준으로 예측되었으므로 다시 원본 이미지 비율로 계산\n",
        "            left = detection[3] * cols\n",
        "            top = detection[4] * rows\n",
        "            right = detection[5] * cols\n",
        "            bottom = detection[6] * rows\n",
        "            # labels_to_names_0딕셔너리로 class_id값을 클래스명으로 변경.\n",
        "            caption = \"{}: {:.4f}\".format(labels_to_names_0[class_id], score)\n",
        "            #print(class_id, caption)\n",
        "            #cv2.rectangle()은 인자로 들어온 draw_img에 사각형을 그림. 위치 인자는 반드시 정수형.\n",
        "            cv2.rectangle(img_frame, (int(left), int(top)), (int(right), int(bottom)), color=green_color, thickness=2)\n",
        "            cv2.putText(img_frame, caption, (int(left), int(top - 5)), cv2.FONT_HERSHEY_SIMPLEX, 0.5, red_color, 1)\n",
        "    print('Detection 수행 시간:', round(time.time()-start, 2),'초')\n",
        "    vid_writer.write(img_frame)\n",
        "# end of while loop\n",
        "\n",
        "vid_writer.release()\n",
        "cap.release()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detection 수행 시간: 7.51 초\n",
            "Detection 수행 시간: 7.32 초\n",
            "Detection 수행 시간: 6.29 초\n",
            "Detection 수행 시간: 7.31 초\n",
            "Detection 수행 시간: 6.41 초\n",
            "Detection 수행 시간: 7.32 초\n",
            "Detection 수행 시간: 6.48 초\n",
            "Detection 수행 시간: 7.35 초\n",
            "Detection 수행 시간: 7.21 초\n",
            "Detection 수행 시간: 6.7 초\n",
            "Detection 수행 시간: 7.24 초\n",
            "Detection 수행 시간: 6.4 초\n",
            "Detection 수행 시간: 7.36 초\n",
            "Detection 수행 시간: 6.32 초\n",
            "Detection 수행 시간: 7.35 초\n",
            "Detection 수행 시간: 6.36 초\n",
            "Detection 수행 시간: 7.33 초\n",
            "Detection 수행 시간: 6.95 초\n",
            "Detection 수행 시간: 7.96 초\n",
            "Detection 수행 시간: 6.38 초\n",
            "Detection 수행 시간: 7.29 초\n",
            "Detection 수행 시간: 6.83 초\n",
            "Detection 수행 시간: 6.93 초\n",
            "Detection 수행 시간: 7.3 초\n",
            "Detection 수행 시간: 6.49 초\n",
            "Detection 수행 시간: 7.32 초\n",
            "Detection 수행 시간: 6.33 초\n",
            "Detection 수행 시간: 7.33 초\n",
            "Detection 수행 시간: 6.29 초\n",
            "Detection 수행 시간: 7.34 초\n",
            "Detection 수행 시간: 6.35 초\n",
            "Detection 수행 시간: 7.27 초\n",
            "Detection 수행 시간: 6.31 초\n",
            "Detection 수행 시간: 7.35 초\n",
            "Detection 수행 시간: 6.38 초\n",
            "Detection 수행 시간: 7.19 초\n",
            "Detection 수행 시간: 6.83 초\n",
            "Detection 수행 시간: 6.81 초\n",
            "Detection 수행 시간: 7.21 초\n",
            "Detection 수행 시간: 6.48 초\n",
            "Detection 수행 시간: 7.72 초\n",
            "Detection 수행 시간: 9.97 초\n",
            "Detection 수행 시간: 7.26 초\n",
            "Detection 수행 시간: 7.03 초\n",
            "Detection 수행 시간: 6.66 초\n",
            "Detection 수행 시간: 7.42 초\n",
            "Detection 수행 시간: 6.43 초\n",
            "Detection 수행 시간: 7.41 초\n",
            "Detection 수행 시간: 6.29 초\n",
            "Detection 수행 시간: 7.4 초\n",
            "Detection 수행 시간: 6.38 초\n",
            "Detection 수행 시간: 7.37 초\n",
            "Detection 수행 시간: 6.37 초\n",
            "Detection 수행 시간: 7.32 초\n",
            "Detection 수행 시간: 6.45 초\n",
            "Detection 수행 시간: 7.37 초\n",
            "Detection 수행 시간: 6.86 초\n",
            "Detection 수행 시간: 7.62 초\n",
            "Detection 수행 시간: 7.43 초\n",
            "Detection 수행 시간: 6.35 초\n",
            "Detection 수행 시간: 7.5 초\n",
            "Detection 수행 시간: 6.34 초\n",
            "Detection 수행 시간: 7.33 초\n",
            "Detection 수행 시간: 6.3 초\n",
            "Detection 수행 시간: 7.4 초\n",
            "더 이상 처리할 frame이 없습니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q9jXeIBrQfAG"
      },
      "source": [
        "#### video detection 전용 함수 생성."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_detected_img(cv_net, img_array, score_threshold, use_copied_array=True, is_print=True):\n",
        "\n",
        "    rows = img_array.shape[0]\n",
        "    cols = img_array.shape[1]\n",
        "\n",
        "    draw_img = None\n",
        "    if use_copied_array:\n",
        "        draw_img = img_array.copy()\n",
        "    else:\n",
        "        draw_img = img_array\n",
        "\n",
        "    cv_net.setInput(cv2.dnn.blobFromImage(img_array, swapRB=True, crop=False))\n",
        "\n",
        "    start = time.time()\n",
        "    cv_out = cv_net.forward()\n",
        "\n",
        "    green_color=(0, 255, 0)\n",
        "    red_color=(0, 0, 255)\n",
        "\n",
        "    # detected 된 object들을 iteration 하면서 정보 추출\n",
        "    for detection in cv_out[0,0,:,:]:\n",
        "        score = float(detection[2])\n",
        "        class_id = int(detection[1])\n",
        "        # detected된 object들의 score가 함수 인자로 들어온 score_threshold 이상만 추출\n",
        "        if score > score_threshold:\n",
        "            # detected된 object들은 scale된 기준으로 예측되었으므로 다시 원본 이미지 비율로 계산\n",
        "            left = detection[3] * cols\n",
        "            top = detection[4] * rows\n",
        "            right = detection[5] * cols\n",
        "            bottom = detection[6] * rows\n",
        "            # labels_to_names 딕셔너리로 class_id값을 클래스명으로 변경. opencv에서는 class_id + 1로 매핑해야함.\n",
        "            caption = \"{}: {:.4f}\".format(labels_to_names_0[class_id], score)\n",
        "            print(caption)\n",
        "            #cv2.rectangle()은 인자로 들어온 draw_img에 사각형을 그림. 위치 인자는 반드시 정수형.\n",
        "            cv2.rectangle(draw_img, (int(left), int(top)), (int(right), int(bottom)), color=green_color, thickness=2)\n",
        "            cv2.putText(draw_img, caption, (int(left), int(top - 5)), cv2.FONT_HERSHEY_SIMPLEX, 0.4, red_color, 1)\n",
        "    if is_print:\n",
        "        print('Detection 수행시간:',round(time.time() - start, 2),\"초\")\n",
        "\n",
        "    return draw_img"
      ],
      "metadata": {
        "id": "0D93f09YNcq1"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKONgteuQfAH"
      },
      "source": [
        "def do_detected_video(cv_net, input_path, output_path, score_threshold, is_print):\n",
        "\n",
        "    cap = cv2.VideoCapture(input_path)\n",
        "\n",
        "    codec = cv2.VideoWriter_fourcc(*'XVID')\n",
        "\n",
        "    vid_size = (round(cap.get(cv2.CAP_PROP_FRAME_WIDTH)),round(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)))\n",
        "    vid_fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "    vid_writer = cv2.VideoWriter(output_path, codec, vid_fps, vid_size)\n",
        "\n",
        "    frame_cnt = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    print('총 Frame 갯수:', frame_cnt)\n",
        "\n",
        "    green_color=(0, 255, 0)\n",
        "    red_color=(0, 0, 255)\n",
        "    while True:\n",
        "        hasFrame, img_frame = cap.read()\n",
        "        if not hasFrame:\n",
        "            print('더 이상 처리할 frame이 없습니다.')\n",
        "            break\n",
        "\n",
        "        img_frame = get_detected_img(cv_net, img_frame, score_threshold=score_threshold, use_copied_array=False, is_print=is_print)\n",
        "\n",
        "        vid_writer.write(img_frame)\n",
        "    # end of while loop\n",
        "\n",
        "    vid_writer.release()\n",
        "    cap.release()"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mzwyzcNzQfAH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22439ef1-e152-4323-f49a-8c67d2c4f9bf"
      },
      "source": [
        "do_detected_video(cv_net, '/content/data/golf_video.mp4', './data/golf_video_02.mp4', 0.2, False)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "총 Frame 갯수: 130\n",
            "person: 0.9994\n",
            "handbag: 0.4370\n",
            "person: 0.2217\n",
            "person: 0.9994\n",
            "person: 0.2753\n",
            "handbag: 0.2245\n",
            "person: 0.9997\n",
            "sports ball: 0.4539\n",
            "handbag: 0.2416\n",
            "person: 0.9977\n",
            "sports ball: 0.4563\n",
            "handbag: 0.4263\n",
            "handbag: 0.2276\n",
            "person: 0.9992\n",
            "handbag: 0.2292\n",
            "person: 0.9996\n",
            "handbag: 0.3421\n",
            "person: 0.9991\n",
            "handbag: 0.3245\n",
            "person: 0.9989\n",
            "handbag: 0.2534\n",
            "person: 0.9987\n",
            "backpack: 0.3054\n",
            "handbag: 0.2444\n",
            "person: 0.2343\n",
            "person: 0.9996\n",
            "handbag: 0.2884\n",
            "person: 0.2249\n",
            "person: 0.9997\n",
            "person: 0.2409\n",
            "backpack: 0.2091\n",
            "person: 0.9976\n",
            "person: 0.5755\n",
            "person: 0.9971\n",
            "traffic light: 0.4752\n",
            "traffic light: 0.2494\n",
            "person: 0.2018\n",
            "person: 0.9988\n",
            "handbag: 0.2114\n",
            "person: 0.9986\n",
            "person: 0.8794\n",
            "kite: 0.4334\n",
            "person: 0.9958\n",
            "person: 0.7718\n",
            "person: 0.3000\n",
            "person: 0.9986\n",
            "kite: 0.4047\n",
            "person: 0.9997\n",
            "person: 0.9981\n",
            "person: 0.9971\n",
            "handbag: 0.2128\n",
            "person: 0.9974\n",
            "handbag: 0.2784\n",
            "person: 0.9972\n",
            "kite: 0.4901\n",
            "handbag: 0.3162\n",
            "person: 0.9977\n",
            "person: 0.9992\n",
            "kite: 0.5208\n",
            "person: 0.4768\n",
            "kite: 0.4432\n",
            "kite: 0.4381\n",
            "person: 0.9995\n",
            "kite: 0.4157\n",
            "person: 0.3120\n",
            "kite: 0.2712\n",
            "kite: 0.2120\n",
            "person: 0.9988\n",
            "person: 0.4326\n",
            "handbag: 0.4156\n",
            "person: 0.9993\n",
            "person: 0.2591\n",
            "person: 0.2006\n",
            "person: 0.9973\n",
            "person: 0.9947\n",
            "handbag: 0.4432\n",
            "person: 0.9984\n",
            "baseball glove: 0.2385\n",
            "person: 0.2187\n",
            "person: 0.9990\n",
            "person: 0.9960\n",
            "person: 0.9960\n",
            "handbag: 0.2515\n",
            "backpack: 0.2262\n",
            "handbag: 0.2182\n",
            "person: 0.9779\n",
            "person: 0.7862\n",
            "handbag: 0.3083\n",
            "handbag: 0.2503\n",
            "backpack: 0.2404\n",
            "person: 0.9903\n",
            "person: 0.5724\n",
            "person: 0.9988\n",
            "person: 0.9962\n",
            "kite: 0.4958\n",
            "kite: 0.2423\n",
            "handbag: 0.2059\n",
            "person: 0.9958\n",
            "handbag: 0.3576\n",
            "person: 0.9985\n",
            "person: 0.9980\n",
            "person: 0.9996\n",
            "person: 0.9988\n",
            "backpack: 0.3382\n",
            "handbag: 0.2271\n",
            "person: 0.9963\n",
            "handbag: 0.3372\n",
            "handbag: 0.3111\n",
            "handbag: 0.3020\n",
            "person: 0.9959\n",
            "person: 0.9990\n",
            "handbag: 0.2247\n",
            "person: 0.9996\n",
            "handbag: 0.2098\n",
            "person: 0.9996\n",
            "handbag: 0.2388\n",
            "person: 0.9998\n",
            "handbag: 0.2345\n",
            "person: 0.9995\n",
            "person: 0.9996\n",
            "sports ball: 0.2076\n",
            "person: 0.9994\n",
            "person: 0.9979\n",
            "handbag: 0.2978\n",
            "person: 0.9980\n",
            "handbag: 0.2303\n",
            "person: 0.9987\n",
            "person: 0.9982\n",
            "handbag: 0.2685\n",
            "person: 0.9997\n",
            "person: 0.9981\n",
            "person: 0.9994\n",
            "handbag: 0.4632\n",
            "person: 0.9989\n",
            "handbag: 0.4031\n",
            "person: 0.9990\n",
            "person: 0.9959\n",
            "handbag: 0.5103\n",
            "person: 0.9919\n",
            "handbag: 0.5774\n",
            "person: 0.9885\n",
            "handbag: 0.6236\n",
            "handbag: 0.3883\n",
            "handbag: 0.3532\n",
            "handbag: 0.2795\n",
            "person: 0.9937\n",
            "handbag: 0.3972\n",
            "person: 0.9984\n",
            "handbag: 0.2829\n",
            "person: 0.9926\n",
            "handbag: 0.3945\n",
            "handbag: 0.2151\n",
            "person: 0.9935\n",
            "handbag: 0.3508\n",
            "handbag: 0.3348\n",
            "더 이상 처리할 frame이 없습니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qXYrpnY6QfAI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24a79371-7b6c-4910-bc54-d866d3d87846"
      },
      "source": [
        "import cv2\n",
        "from tqdm import tqdm\n",
        "\n",
        "def do_detected_video(cv_net, input_path, output_path, score_threshold, is_print):\n",
        "\n",
        "    cap = cv2.VideoCapture(input_path)\n",
        "\n",
        "    codec = cv2.VideoWriter_fourcc(*'XVID')\n",
        "\n",
        "    vid_size = (round(cap.get(cv2.CAP_PROP_FRAME_WIDTH)), round(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)))\n",
        "    vid_fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "    vid_writer = cv2.VideoWriter(output_path, codec, vid_fps, vid_size)\n",
        "\n",
        "    frame_cnt = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    print('총 Frame 갯수:', frame_cnt)\n",
        "\n",
        "    green_color = (0, 255, 0)\n",
        "    red_color = (0, 0, 255)\n",
        "\n",
        "    # Use tqdm to display a progress bar\n",
        "    for _ in tqdm(range(frame_cnt), desc=\"Processing Frames\"):\n",
        "        hasFrame, img_frame = cap.read()\n",
        "        if not hasFrame:\n",
        "            print('더 이상 처리할 frame이 없습니다.')\n",
        "            break\n",
        "\n",
        "        img_frame = get_detected_img(cv_net, img_frame, score_threshold=score_threshold, use_copied_array=False, is_print=is_print)\n",
        "\n",
        "        vid_writer.write(img_frame)\n",
        "\n",
        "    vid_writer.release()\n",
        "    cap.release()\n",
        "\n",
        "# Call the function with your parameters\n",
        "do_detected_video(cv_net, 'input_video.mp4', 'output_video.avi', 0.5, True)\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "총 Frame 갯수: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Frames: 0it [00:00, ?it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xL256mPpPbFC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}